{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregation primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.variable_types import (Index, Numeric, Discrete, Boolean,\n",
    "                                         DatetimeTimeIndex, Variable)\n",
    "from .aggregation_primitive_base import (AggregationPrimitive,\n",
    "                                         make_agg_primitive)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "# TODO: make sure get func gets numpy arrays not series\n",
    "\n",
    "\n",
    "class Count(AggregationPrimitive):\n",
    "    \"\"\"Counts the number of non null values\"\"\"\n",
    "    name = \"count\"\n",
    "    input_types = [[Index], [Variable]]\n",
    "    return_type = Numeric\n",
    "    stack_on_self = False\n",
    "    default_value = 0\n",
    "\n",
    "    def __init__(self, id_feature, parent_entity, count_null=False, **kwargs):\n",
    "        self.count_null = count_null\n",
    "        super(Count, self).__init__(id_feature, parent_entity, **kwargs)\n",
    "\n",
    "    def get_function(self):\n",
    "        def func(values, count_null=self.count_null):\n",
    "            if len(values) == 0:\n",
    "                return 0\n",
    "\n",
    "            if count_null:\n",
    "                values = values.fillna(0)\n",
    "\n",
    "            return values.count()\n",
    "        return func\n",
    "\n",
    "    def _get_name(self):\n",
    "        where_str = self._where_str()\n",
    "        use_prev_str = self._use_prev_str()\n",
    "\n",
    "        return u\"COUNT(%s%s%s)\" % (self.child_entity.name,\n",
    "                                   where_str, use_prev_str)\n",
    "\n",
    "\n",
    "class Sum(AggregationPrimitive):\n",
    "    \"\"\"Counts the number of elements of a numeric or boolean feature\"\"\"\n",
    "    name = \"sum\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "    stack_on_self = False\n",
    "    stack_on_exclude = [Count]\n",
    "\n",
    "    # todo: handle count nulls\n",
    "    def get_function(self):\n",
    "        def sum_func(x):\n",
    "            return np.nan_to_num(x.values).sum(dtype=np.float)\n",
    "        return sum_func\n",
    "\n",
    "\n",
    "class Mean(AggregationPrimitive):\n",
    "    \"\"\"Computes the average value of a numeric feature\"\"\"\n",
    "    name = \"mean\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "\n",
    "    # p todo: handle nulls\n",
    "    def get_function(self):\n",
    "        return np.nanmean\n",
    "\n",
    "\n",
    "class Mode(AggregationPrimitive):\n",
    "    \"\"\"Finds the most common element in a categorical feature\"\"\"\n",
    "    name = \"mode\"\n",
    "    input_types = [Discrete]\n",
    "    return_type = None\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_mode(x):\n",
    "            if x.mode().shape[0] == 0:\n",
    "                return np.nan\n",
    "            return x.mode().iloc[0]\n",
    "        return pd_mode\n",
    "\n",
    "\n",
    "Min = make_agg_primitive(\n",
    "    np.min,\n",
    "    [Numeric],\n",
    "    None,\n",
    "    name=\"min\",\n",
    "    stack_on_self=False,\n",
    "    description=\"Finds the minimum non-null value of a numeric feature.\")\n",
    "\n",
    "\n",
    "# class Min(AggregationPrimitive):\n",
    "#     \"\"\"Finds the minimum non-null value of a numeric feature.\"\"\"\n",
    "#     name = \"min\"\n",
    "#     input_types =  [Numeric]\n",
    "#     return_type = None\n",
    "#     # max_stack_depth = 1\n",
    "#     stack_on_self = False\n",
    "\n",
    "#     def get_function(self):\n",
    "#         return np.min\n",
    "\n",
    "\n",
    "class Max(AggregationPrimitive):\n",
    "    \"\"\"Finds the maximum non-null value of a numeric feature\"\"\"\n",
    "    name = \"max\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = None\n",
    "    # max_stack_depth = 1\n",
    "    stack_on_self = False\n",
    "\n",
    "    def get_function(self):\n",
    "        return np.max\n",
    "\n",
    "\n",
    "class NUnique(AggregationPrimitive):\n",
    "    \"\"\"Returns the number of unique categorical variables\"\"\"\n",
    "    name = \"num_unique\"\n",
    "    # todo can we use discrete in input_types instead?\n",
    "    input_types = [Discrete]\n",
    "    return_type = Numeric\n",
    "    # max_stack_depth = 1\n",
    "    stack_on_self = False\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda x: x.nunique()\n",
    "\n",
    "\n",
    "class NumTrue(AggregationPrimitive):\n",
    "    \"\"\"Finds the number of 'True' values in a boolean\"\"\"\n",
    "    name = \"num_true\"\n",
    "    input_types = [Boolean]\n",
    "    return_type = Numeric\n",
    "    default_value = 0\n",
    "    stack_on = []\n",
    "    stack_on_exclude = []\n",
    "\n",
    "    def get_function(self):\n",
    "        def num_true(x):\n",
    "            return np.nan_to_num(x.values).sum()\n",
    "        return num_true\n",
    "\n",
    "\n",
    "class PercentTrue(AggregationPrimitive):\n",
    "    \"\"\"Finds the percent of 'True' values in a boolean feature\"\"\"\n",
    "    name = \"percent_true\"\n",
    "    input_types = [Boolean]\n",
    "    return_type = Numeric\n",
    "    max_stack_depth = 1\n",
    "    stack_on = []\n",
    "    stack_on_exclude = []\n",
    "\n",
    "    def get_function(self):\n",
    "        def percent_true(x):\n",
    "            if len(x) == 0:\n",
    "                return np.nan\n",
    "            return np.nan_to_num(x.values).sum(dtype=np.float) / len(x)\n",
    "        return percent_true\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "最喜爱的top_n 产品/股票/行业/……\n",
    "'''\n",
    "class NMostCommon(AggregationPrimitive):\n",
    "    \"\"\"Finds the N most common elements in a categorical feature\"\"\"\n",
    "    name = \"n_most_common\"\n",
    "    input_types = [Discrete]\n",
    "    return_type = Discrete\n",
    "    # max_stack_depth = 1\n",
    "    stack_on = []\n",
    "    stack_on_exclude = []\n",
    "    expanding = True\n",
    "\n",
    "    def __init__(self, base_feature, parent_entity, n=3):\n",
    "        self.n = n\n",
    "        super(NMostCommon, self).__init__(base_feature, parent_entity)\n",
    "\n",
    "    @property\n",
    "    def default_value(self):\n",
    "        return np.zeros(self.n) * np.nan\n",
    "\n",
    "    def get_expanded_names(self):\n",
    "        names = []\n",
    "        for i in range(1, self.n + 1):\n",
    "            names.append(str(i) + self.get_name()[1:])\n",
    "        return names\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_topn(x, n=self.n):\n",
    "            return np.array(x.value_counts()[:n].index)\n",
    "        return pd_topn\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "客户平均登录时长/平均购买**产品间隔/……\n",
    "'''\n",
    "class AvgTimeBetween(AggregationPrimitive):\n",
    "    \"\"\"Computes the average time between consecutive events\n",
    "    using the time index of the entity.\n",
    "    Note: equivalent to Mean(Diff(time_index)), but more performant\n",
    "    \"\"\"\n",
    "\n",
    "    # Potentially unnecessary if we add an trans_feat that\n",
    "    # calculates the difference between events. DFS\n",
    "    # should then calculate the average of that trans_feat\n",
    "    # which amounts to AvgTimeBetween\n",
    "    name = \"avg_time_between\"\n",
    "    input_types = [DatetimeTimeIndex]\n",
    "    return_type = Numeric\n",
    "    # max_stack_depth = 1\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_avg_time_between(x):\n",
    "            \"\"\"\n",
    "            Assumes time scales are closer to order\n",
    "            of seconds than to nanoseconds\n",
    "            if times are much closer to nanoseconds\n",
    "            we could get some floating point errors\n",
    "            this can be fixed with another function\n",
    "            that calculates the mean before converting\n",
    "            to seconds\n",
    "            \"\"\"\n",
    "            x = x.dropna()\n",
    "            if x.shape[0] < 2:\n",
    "                return np.nan\n",
    "            if isinstance(x.iloc[0], (pd.Timestamp, datetime)):\n",
    "                x = x.astype('int64')\n",
    "                # use len(x)-1 because we care about difference\n",
    "                # between values, len(x)-1 = len(diff(x))\n",
    "                avg = ((x.max() - x.min())) / float(len(x) - 1)\n",
    "            else:\n",
    "                avg = (x.max() - x.min()) / float(len(x) - 1)\n",
    "\n",
    "            avg = avg * 1e-9\n",
    "\n",
    "            # long form:\n",
    "            # diff_in_ns = x.diff().iloc[1:].astype('int64')\n",
    "            # diff_in_seconds = diff_in_ns * 1e-9\n",
    "            # avg = diff_in_seconds.mean()\n",
    "            return avg\n",
    "        return pd_avg_time_between\n",
    "\n",
    "\n",
    "class Median(AggregationPrimitive):\n",
    "    \"\"\"Finds the median value of any feature with well-ordered values\"\"\"\n",
    "    name = \"median\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = None\n",
    "    # max_stack_depth = 2\n",
    "\n",
    "    def get_function(self):\n",
    "        return np.median\n",
    "\n",
    "\n",
    "class Skew(AggregationPrimitive):\n",
    "    \"\"\"Computes the skewness of a data set.\n",
    "    For normally distributed data, the skewness should be about 0. A skewness\n",
    "    value > 0 means that there is more weight in the left tail of the\n",
    "    distribution.\n",
    "    \"\"\"\n",
    "    name = \"skew\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "    stack_on = []\n",
    "    stack_on_self = False\n",
    "    # max_stack_depth = 1\n",
    "\n",
    "    def get_function(self):\n",
    "        return skew\n",
    "\n",
    "\n",
    "class Std(AggregationPrimitive):\n",
    "    \"\"\"\n",
    "    Finds the standard deviation of a numeric feature ignoring null values.\n",
    "    \"\"\"\n",
    "    name = \"std\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "    # max_stack_depth = 2\n",
    "    stack_on_self = False\n",
    "\n",
    "    def get_function(self):\n",
    "        return np.nanstd\n",
    "\n",
    "\n",
    "class Last(AggregationPrimitive):\n",
    "    \"\"\"Returns the last value\"\"\"\n",
    "    name = \"last\"\n",
    "    input_types = [Variable]\n",
    "    return_type = None\n",
    "    stack_on_self = False\n",
    "    # max_stack_depth = 1\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_last(x):\n",
    "            return x.iloc[-1]\n",
    "        return pd_last\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "客户最近一年是否 买过**产品/登录过app/……\n",
    "'''\n",
    "class Any(AggregationPrimitive):\n",
    "    \"\"\"Test if any value is True\"\"\"\n",
    "    name = \"any\"\n",
    "    input_types = [Boolean]\n",
    "    return_type = Boolean\n",
    "    stack_on_self = False\n",
    "\n",
    "    def get_function(self):\n",
    "        return np.any\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "客户最近n个月连续 买过**产品/登录过app/……\n",
    "'''\n",
    "class All(AggregationPrimitive):\n",
    "    \"\"\"Test if all values are True\"\"\"\n",
    "    name = \"all\"\n",
    "    input_types = [Boolean]\n",
    "    return_type = Boolean\n",
    "    stack_on_self = False\n",
    "\n",
    "    def get_function(self):\n",
    "        return np.all\n",
    "\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "客户多久没有 买过**产品/登录过app/……\n",
    "'''\n",
    "class TimeSinceLast(AggregationPrimitive):\n",
    "    \"\"\"Time since last related instance\"\"\"\n",
    "    name = \"time_since_last\"\n",
    "    input_types = [DatetimeTimeIndex]\n",
    "    return_type = Numeric\n",
    "    uses_calc_time = True\n",
    "\n",
    "    def get_function(self):\n",
    "\n",
    "        def time_since_last(values, time=None):\n",
    "            time_since = time - values.iloc[0]\n",
    "            return time_since.total_seconds()\n",
    "\n",
    "        return time_since_last\n",
    "\n",
    "\n",
    "'''\n",
    "函数应用举例：\n",
    "客户资产下降/上升速度\n",
    "'''\n",
    "class Trend(AggregationPrimitive):\n",
    "    \"\"\"Calculates the slope of the linear trend of variable overtime\"\"\"\n",
    "    name = \"trend\"\n",
    "    input_types = [Numeric, DatetimeTimeIndex]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def __init__(self, value, time_index, parent_entity, **kwargs):\n",
    "        self.value = value\n",
    "        self.time_index = time_index\n",
    "        super(Trend, self).__init__([value, time_index],\n",
    "                                    parent_entity,\n",
    "                                    **kwargs)\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_trend(y, x):\n",
    "            df = pd.DataFrame({\"x\": x, \"y\": y}).dropna()\n",
    "            if df.shape[0] <= 2:\n",
    "                return np.nan\n",
    "            if isinstance(df['x'].iloc[0], (datetime, pd.Timestamp)):\n",
    "                x = convert_datetime_to_floats(df['x'])\n",
    "            else:\n",
    "                x = df['x'].values\n",
    "\n",
    "            if isinstance(df['y'].iloc[0], (datetime, pd.Timestamp)):\n",
    "                y = convert_datetime_to_floats(df['y'])\n",
    "            elif isinstance(df['y'].iloc[0], (timedelta, pd.Timedelta)):\n",
    "                y = convert_timedelta_to_floats(df['y'])\n",
    "            else:\n",
    "                y = df['y'].values\n",
    "\n",
    "            x = x - x.mean()\n",
    "            y = y - y.mean()\n",
    "\n",
    "            # prevent divide by zero error\n",
    "            if len(np.unique(x)) == 1:\n",
    "                return 0\n",
    "\n",
    "            # consider scipy.stats.linregress for large n cases\n",
    "            coefficients = np.polyfit(x, y, 1)\n",
    "\n",
    "            return coefficients[0]\n",
    "        return pd_trend\n",
    "\n",
    "\n",
    "# # TODO: Not implemented yet\n",
    "# class ConseqPos(AggregationPrimitive):\n",
    "#     name = \"conseq_pos\"\n",
    "#     input_types =  [(variable_types.Numeric,),\n",
    "#                 (variable_types.Ordinal,)]\n",
    "#     return_type = variable_types.Numeric\n",
    "#     max_stack_depth = 1\n",
    "#     stack_on = []\n",
    "#     stack_on_exclude = []\n",
    "\n",
    "#     def get_function(self):\n",
    "#         raise NotImplementedError(\"This feature has not been implemented\")\n",
    "\n",
    "\n",
    "# # TODO: Not implemented yet\n",
    "# class ConseqSame(AggregationPrimitive):\n",
    "#     name = \"conseq_same\"\n",
    "#     input_types =  [(variable_types.Categorical,),\n",
    "#                 (variable_types.Ordinal,),\n",
    "#                 (variable_types.Numeric,)]\n",
    "#     return_type = variable_types.Numeric\n",
    "#     max_stack_depth = 1\n",
    "#     stack_on = []\n",
    "#     stack_on_exclude = []\n",
    "\n",
    "#     def get_function(self):\n",
    "#         raise NotImplementedError(\"This feature has not been implemented\")\n",
    "\n",
    "\n",
    "# # TODO: Not implemented yet\n",
    "# class TimeSinceLast(AggregationPrimitive):\n",
    "\n",
    "\n",
    "def convert_datetime_to_floats(x):\n",
    "    first = int(x.iloc[0].value * 1e-9)\n",
    "    x = pd.to_numeric(x).astype(np.float64).values\n",
    "    dividend = find_dividend_by_unit(first)\n",
    "    x *= (1e-9 / dividend)\n",
    "    return x\n",
    "\n",
    "\n",
    "def convert_timedelta_to_floats(x):\n",
    "    first = int(x.iloc[0].total_seconds())\n",
    "    dividend = find_dividend_by_unit(first)\n",
    "    x = pd.TimedeltaIndex(x).total_seconds().astype(np.float64) / dividend\n",
    "    return x\n",
    "\n",
    "\n",
    "def find_dividend_by_unit(time):\n",
    "    \"\"\"\n",
    "    Finds whether time best corresponds to a value in\n",
    "    days, hours, minutes, or seconds\n",
    "    \"\"\"\n",
    "    for dividend in [86400., 3600., 60.]:\n",
    "        div = time / dividend\n",
    "        if round(div) == div:\n",
    "            return dividend\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom .primitive_base import PrimitiveBase\n",
    "from .utils import inspect_function_args\n",
    "from featuretools.variable_types import (Discrete, Numeric, Boolean,\n",
    "                                         Ordinal, Datetime, Timedelta,\n",
    "                                         Variable, DatetimeTimeIndex, Id)\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "current_path = os.path.dirname(os.path.realpath(__file__))\n",
    "FEATURE_DATASETS = os.path.join(os.path.join(current_path, '..'),\n",
    "                                'feature_datasets')\n",
    "\n",
    "\n",
    "class TransformPrimitive(PrimitiveBase):\n",
    "    \"\"\"Feature for entity that is a based off one or more other features\n",
    "        in that entity\"\"\"\n",
    "    rolling_function = False\n",
    "\n",
    "    def __init__(self, *base_features):\n",
    "        # Any edits made to this method should also be made to the\n",
    "        # new_class_init method in make_trans_primitive\n",
    "        self.base_features = [self._check_feature(f) for f in base_features]\n",
    "        if any(bf.expanding for bf in self.base_features):\n",
    "            self.expanding = True\n",
    "        assert len(set([f.entity for f in self.base_features])) == 1, \\\n",
    "            \"More than one entity for base features\"\n",
    "        super(TransformPrimitive, self).__init__(self.base_features[0].entity,\n",
    "                                                 self.base_features)\n",
    "\n",
    "    def _get_name(self):\n",
    "        name = u\"{}(\".format(self.name.upper())\n",
    "        name += u\", \".join(f.get_name() for f in self.base_features)\n",
    "        name += u\")\"\n",
    "        return name\n",
    "\n",
    "    @property\n",
    "    def default_value(self):\n",
    "        return self.base_features[0].default_value\n",
    "\n",
    "\n",
    "def make_trans_primitive(function, input_types, return_type, name=None,\n",
    "                         description='A custom transform primitive',\n",
    "                         cls_attributes=None, uses_calc_time=False,\n",
    "                         associative=False):\n",
    "    '''Returns a new transform primitive class\n",
    "    Args:\n",
    "        function (function): function that takes in an array  and applies some\n",
    "            transformation to it.\n",
    "        name (string): name of the function\n",
    "        input_types (list[:class:`.Variable`]): variable types of the inputs\n",
    "        return_type (:class:`.Variable`): variable type of return\n",
    "        description (string): description of primitive\n",
    "        cls_attributes (dict): custom attributes to be added to class\n",
    "        uses_calc_time (bool): if True, the cutoff time the feature is being\n",
    "            calculated at will be passed to the function as the keyword\n",
    "            argument 'time'.\n",
    "        associative (bool): If True, will only make one feature per unique set\n",
    "            of base features\n",
    "    Example:\n",
    "        .. ipython :: python\n",
    "            from featuretools.primitives import make_trans_primitive\n",
    "            from featuretools.variable_types import Variable, Boolean\n",
    "            def pd_is_in(array, list_of_outputs=None):\n",
    "                if list_of_outputs is None:\n",
    "                    list_of_outputs = []\n",
    "                return pd.Series(array).isin(list_of_outputs)\n",
    "            def isin_get_name(self):\n",
    "                return u\"%s.isin(%s)\" % (self.base_features[0].get_name(),\n",
    "                                         str(self.kwargs['list_of_outputs']))\n",
    "            IsIn = make_trans_primitive(\n",
    "                pd_is_in,\n",
    "                [Variable],\n",
    "                Boolean,\n",
    "                name=\"is_in\",\n",
    "                description=\"For each value of the base feature, checks \"\n",
    "                \"whether it is in a list that provided.\",\n",
    "                cls_attributes={\"_get_name\": isin_get_name})\n",
    "    '''\n",
    "    # dictionary that holds attributes for class\n",
    "    cls = {\"__doc__\": description}\n",
    "    if cls_attributes is not None:\n",
    "        cls.update(cls_attributes)\n",
    "\n",
    "    # creates the new class and set name and types\n",
    "    name = name or function.func_name\n",
    "    new_class = type(name, (TransformPrimitive,), cls)\n",
    "    new_class.name = name\n",
    "    new_class.input_types = input_types\n",
    "    new_class.return_type = return_type\n",
    "    new_class.associative = associative\n",
    "    new_class, kwargs = inspect_function_args(new_class,\n",
    "                                              function,\n",
    "                                              uses_calc_time)\n",
    "\n",
    "    if kwargs is not None:\n",
    "        new_class.kwargs = kwargs\n",
    "\n",
    "        def new_class_init(self, *args, **kwargs):\n",
    "            self.base_features = [self._check_feature(f) for f in args]\n",
    "            if any(bf.expanding for bf in self.base_features):\n",
    "                self.expanding = True\n",
    "            assert len(set([f.entity for f in self.base_features])) == 1, \\\n",
    "                \"More than one entity for base features\"\n",
    "            self.kwargs.update(kwargs)\n",
    "            self.partial = functools.partial(function, **self.kwargs)\n",
    "            super(TransformPrimitive, self).__init__(\n",
    "                self.base_features[0].entity, self.base_features)\n",
    "        new_class.__init__ = new_class_init\n",
    "        new_class.get_function = lambda self: self.partial\n",
    "    else:\n",
    "        # creates a lambda function that returns function every time\n",
    "        new_class.get_function = lambda self, f=function: f\n",
    "\n",
    "    return new_class\n",
    "\n",
    "\n",
    "class IsNull(TransformPrimitive):\n",
    "    \"\"\"For each value of base feature, return true if value is null\"\"\"\n",
    "    name = \"is_null\"\n",
    "    input_types = [Variable]\n",
    "    return_type = Boolean\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: pd.isnull(pd.Series(array))\n",
    "\n",
    "\n",
    "class Absolute(TransformPrimitive):\n",
    "    \"\"\"Absolute value of base feature\"\"\"\n",
    "    name = \"absolute\"\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: np.absolute(array)\n",
    "\n",
    "\n",
    "class TimeSincePrevious(TransformPrimitive):\n",
    "    \"\"\"Compute the time since the previous instance for each instance in a\n",
    "     time indexed entity\"\"\"\n",
    "    name = \"time_since_previous\"\n",
    "    input_types = [DatetimeTimeIndex, Id]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def __init__(self, time_index, group_feature):\n",
    "        \"\"\"Summary\n",
    "        Args:\n",
    "            base_feature (:class:`PrimitiveBase`): base feature\n",
    "            group_feature (None, optional): variable or feature to group\n",
    "                rows by before calculating diff\n",
    "        \"\"\"\n",
    "        group_feature = self._check_feature(group_feature)\n",
    "        assert issubclass(group_feature.variable_type, Discrete), \\\n",
    "            \"group_feature must have a discrete variable_type\"\n",
    "        self.group_feature = group_feature\n",
    "        super(TimeSincePrevious, self).__init__(time_index, group_feature)\n",
    "\n",
    "    def _get_name(self):\n",
    "        return u\"time_since_previous_by_%s\" % self.group_feature.get_name()\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_diff(base_array, group_array):\n",
    "            bf_name = 'base_feature'\n",
    "            groupby = 'groupby'\n",
    "            grouped_df = pd.DataFrame.from_dict({bf_name: base_array,\n",
    "                                                 groupby: group_array})\n",
    "            grouped_df = grouped_df.groupby(groupby).diff()\n",
    "            return grouped_df[bf_name].apply(lambda x:\n",
    "                                             x.total_seconds())\n",
    "        return pd_diff\n",
    "\n",
    "\n",
    "class DatetimeUnitBasePrimitive(TransformPrimitive):\n",
    "    \"\"\"Transform Datetime feature into time or calendar units\n",
    "     (second/day/week/etc)\"\"\"\n",
    "    name = None\n",
    "    input_types = [Datetime]\n",
    "    return_type = Ordinal\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: pd_time_unit(self.name)(pd.DatetimeIndex(array))\n",
    "\n",
    "\n",
    "class TimedeltaUnitBasePrimitive(TransformPrimitive):\n",
    "    \"\"\"Transform Timedelta features into number of time units\n",
    "     (seconds/days/etc) they encompass\"\"\"\n",
    "    name = None\n",
    "    input_types = [Timedelta]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: pd_time_unit(self.name)(pd.TimedeltaIndex(array))\n",
    "\n",
    "\n",
    "class Day(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the day\"\"\"\n",
    "    name = \"day\"\n",
    "\n",
    "\n",
    "class Days(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of days\"\"\"\n",
    "    name = \"days\"\n",
    "\n",
    "\n",
    "class Hour(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the hour\"\"\"\n",
    "    name = \"hour\"\n",
    "\n",
    "\n",
    "class Hours(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of hours\"\"\"\n",
    "    name = \"hours\"\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_hours(array):\n",
    "            return pd_time_unit(\"seconds\")(pd.TimedeltaIndex(array)) / 3600.\n",
    "        return pd_hours\n",
    "\n",
    "\n",
    "class Second(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the second\"\"\"\n",
    "    name = \"second\"\n",
    "\n",
    "\n",
    "class Seconds(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of seconds\"\"\"\n",
    "    name = \"seconds\"\n",
    "\n",
    "\n",
    "class Minute(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the minute\"\"\"\n",
    "    name = \"minute\"\n",
    "\n",
    "\n",
    "class Minutes(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of minutes\"\"\"\n",
    "    name = \"minutes\"\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_minutes(array):\n",
    "            return pd_time_unit(\"seconds\")(pd.TimedeltaIndex(array)) / 60.\n",
    "        return pd_minutes\n",
    "\n",
    "\n",
    "class Week(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the week\"\"\"\n",
    "    name = \"week\"\n",
    "\n",
    "\n",
    "class Weeks(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of weeks\"\"\"\n",
    "    name = \"weeks\"\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_weeks(array):\n",
    "            return pd_time_unit(\"days\")(pd.TimedeltaIndex(array)) / 7.\n",
    "        return pd_weeks\n",
    "\n",
    "\n",
    "class Month(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the month\"\"\"\n",
    "    name = \"month\"\n",
    "\n",
    "\n",
    "class Months(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of months\"\"\"\n",
    "    name = \"months\"\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_months(array):\n",
    "            return pd_time_unit(\"days\")(pd.TimedeltaIndex(array)) * (12. / 365)\n",
    "        return pd_months\n",
    "\n",
    "\n",
    "class Year(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform a Datetime feature into the year\"\"\"\n",
    "    name = \"year\"\n",
    "\n",
    "\n",
    "class Years(TimedeltaUnitBasePrimitive):\n",
    "    \"\"\"Transform a Timedelta feature into the number of years\"\"\"\n",
    "    name = \"years\"\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_years(array):\n",
    "            return pd_time_unit(\"days\")(pd.TimedeltaIndex(array)) / 365\n",
    "        return pd_years\n",
    "\n",
    "\n",
    "class Weekend(TransformPrimitive):\n",
    "    \"\"\"Transform Datetime feature into the boolean of Weekend\"\"\"\n",
    "    name = \"is_weekend\"\n",
    "    input_types = [Datetime]\n",
    "    return_type = Boolean\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda df: pd_time_unit(\"weekday\")(pd.DatetimeIndex(df)) > 4\n",
    "\n",
    "\n",
    "class Weekday(DatetimeUnitBasePrimitive):\n",
    "    \"\"\"Transform Datetime feature into the boolean of Weekday\"\"\"\n",
    "    name = \"weekday\"\n",
    "\n",
    "\n",
    "# class Like(TransformPrimitive):\n",
    "#     \"\"\"Equivalent to SQL LIKE(%text%)\n",
    "#        Returns true if text is contained with the string base_feature\n",
    "#     \"\"\"\n",
    "#     name = \"like\"\n",
    "#     input_types =  [(Text,), (Categorical,)]\n",
    "#     return_type = Boolean\n",
    "\n",
    "#     def __init__(self, base_feature, like_statement, case_sensitive=False):\n",
    "#         self.like_statement = like_statement\n",
    "#         self.case_sensitive = case_sensitive\n",
    "#         super(Like, self).__init__(base_feature)\n",
    "\n",
    "#     def get_function(self):\n",
    "#         def pd_like(df, f):\n",
    "#             return df[df.columns[0]].str.contains(f.like_statement,\n",
    "#                                                   case=f.case_sensitive)\n",
    "#         return pd_like\n",
    "\n",
    "\n",
    "# class TimeSince(TransformPrimitive):\n",
    "#     \"\"\"\n",
    "#     For each value of the base feature, compute the timedelta between it and\n",
    "#     a datetime\n",
    "#     \"\"\"\n",
    "#     name = \"time_since\"\n",
    "#     input_types = [[DatetimeTimeIndex], [Datetime]]\n",
    "#     return_type = Timedelta\n",
    "#     uses_calc_time = True\n",
    "\n",
    "#     def get_function(self):\n",
    "#         def pd_time_since(array, time):\n",
    "#             if time is None:\n",
    "#                 time = datetime.now()\n",
    "#             return (time - pd.DatetimeIndex(array)).values\n",
    "#         return pd_time_since\n",
    "\n",
    "\n",
    "def pd_time_since(array, time):\n",
    "    if time is None:\n",
    "        time = datetime.now()\n",
    "    return (time - pd.DatetimeIndex(array)).values\n",
    "\n",
    "\n",
    "TimeSince = make_trans_primitive(function=pd_time_since,\n",
    "                                 input_types=[[DatetimeTimeIndex], [Datetime]],\n",
    "                                 return_type=Timedelta,\n",
    "                                 uses_calc_time=True,\n",
    "                                 name=\"time_since\")\n",
    "\n",
    "\n",
    "class DaysSince(TransformPrimitive):\n",
    "    \"\"\"\n",
    "    For each value of the base feature, compute the number of days between it\n",
    "    and a datetime\n",
    "    \"\"\"\n",
    "    name = \"days_since\"\n",
    "    input_types = [DatetimeTimeIndex]\n",
    "    return_type = Numeric\n",
    "    uses_calc_time = True\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_days_since(array, time):\n",
    "            if time is None:\n",
    "                time = datetime.now()\n",
    "            return pd_time_unit('days')(time - pd.DatetimeIndex(array))\n",
    "        return pd_days_since\n",
    "\n",
    "\n",
    "\n",
    "class IsIn(TransformPrimitive):\n",
    "    \"\"\"\n",
    "    For each value of the base feature, checks whether it is in a list that is\n",
    "    provided.\n",
    "    \"\"\"\n",
    "    name = \"isin\"\n",
    "    input_types = [Variable]\n",
    "    return_type = Boolean\n",
    "\n",
    "    def __init__(self, base_feature, list_of_outputs=None):\n",
    "        self.list_of_outputs = list_of_outputs\n",
    "        super(IsIn, self).__init__(base_feature)\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_is_in(array, list_of_outputs=self.list_of_outputs):\n",
    "            if list_of_outputs is None:\n",
    "                list_of_outputs = []\n",
    "            return pd.Series(array).isin(list_of_outputs)\n",
    "        return pd_is_in\n",
    "\n",
    "    def _get_name(self):\n",
    "        return u\"%s.isin(%s)\" % (self.base_features[0].get_name(),\n",
    "                                 str(self.list_of_outputs))\n",
    "\n",
    "\n",
    "class Diff(TransformPrimitive):\n",
    "    \"\"\"\n",
    "    For each value of the base feature, compute the difference between it and\n",
    "    the previous value.\n",
    "    If it is a Datetime feature, compute the difference in seconds\n",
    "    \"\"\"\n",
    "    name = \"diff\"\n",
    "    input_types = [Numeric, Id]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def __init__(self, base_feature, group_feature):\n",
    "        \"\"\"Summary\n",
    "        Args:\n",
    "            base_feature (:class:`PrimitiveBase`): base feature\n",
    "            group_feature (:class:`PrimitiveBase`): variable or feature to\n",
    "                group rows by before calculating diff\n",
    "        \"\"\"\n",
    "        self.group_feature = self._check_feature(group_feature)\n",
    "        super(Diff, self).__init__(base_feature, group_feature)\n",
    "\n",
    "    def _get_name(self):\n",
    "        base_features_str = self.base_features[0].get_name() + u\" by \" + \\\n",
    "            self.group_feature.get_name()\n",
    "        return u\"%s(%s)\" % (self.name.upper(), base_features_str)\n",
    "\n",
    "    def get_function(self):\n",
    "        def pd_diff(base_array, group_array):\n",
    "            bf_name = 'base_feature'\n",
    "            groupby = 'groupby'\n",
    "            grouped_df = pd.DataFrame.from_dict({bf_name: base_array,\n",
    "                                                 groupby: group_array})\n",
    "            grouped_df = grouped_df.groupby(groupby).diff()\n",
    "            return grouped_df[bf_name]\n",
    "        return pd_diff\n",
    "\n",
    "\n",
    "class Not(TransformPrimitive):\n",
    "    \"\"\"\n",
    "    For each value of the base feature, negates the boolean value.\n",
    "    \"\"\"\n",
    "    name = \"not\"\n",
    "    input_types = [Boolean]\n",
    "    return_type = Boolean\n",
    "\n",
    "    def _get_name(self):\n",
    "        return u\"NOT({})\".format(self.base_features[0].get_name())\n",
    "\n",
    "    def _get_op(self):\n",
    "        return \"__not__\"\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: np.logical_not(array)\n",
    "\n",
    "\n",
    "class Percentile(TransformPrimitive):\n",
    "    \"\"\"\n",
    "    For each value of the base feature, determines the percentile in relation\n",
    "    to the rest of the feature.\n",
    "    \"\"\"\n",
    "    name = 'percentile'\n",
    "    input_types = [Numeric]\n",
    "    return_type = Numeric\n",
    "\n",
    "    def get_function(self):\n",
    "        return lambda array: pd.Series(array).rank(pct=True)\n",
    "\n",
    "\n",
    "def pd_time_unit(time_unit):\n",
    "    def inner(pd_index):\n",
    "        return getattr(pd_index, time_unit).values\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
